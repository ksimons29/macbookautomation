Welcome to another week in AI and as per usual releases are not slowing down with innovations
on the automation front on the chat GPT front, there's new voice models, there's new state
of the art video models and easier ways to use them. But today, I really want to lead
with a super, super interesting release which went under the radar for a lot of people.
It's anthropics skills. And basically, this is their version of chat GPT apps, but this
is going to be available in the web interface in cloud code and through their API. And that's
really different from opening eyes approach where it's chat GPT only thing with their apps.
So I've spent about 30 minutes playing with these skills so far. And I think as per usually,
it's best to just show you rather than to tell you about it. Because if I go to my cloud account
here, then head on over to settings. And here on the capabilities, you can see a new skills tab,
and it comes set up with all of these skills that I'm fropping built, you can simply enable these
or upload your own, and they even have a specific skill for creating other skills, which I did.
And I'll show you that in a second. But let's start by looking at some of these skills. So for
example, the brand guidelines one is quite simple. It just contains all the brand guidelines from
anthropic themselves. I'll also turn on canvas design. And I have the skills creator already.
So let's start with the canvas design here, you can just try it in a chat like so,
and I'll alter the prompt. So this makes a movie poster for this YouTube show. So while it does
that, let's talk about what the skills are. Well, it's free things as stated by anthropic.
First of all, instructions, aka prompt for the island to do something. Secondly, its references,
I suppose this is something like examples, but it seems to me that they can come in many forms,
not just text. And thirdly, most importantly, code, kind of obviously, and Claude runs that really
cleanly. So if I look at this canvas design skill right here, let's see what happened here. First
of all, it looked at the skill, where it does a specific thing. It first starts with a design
philosophy in a separate markdown file. And then it creates the actual poster as a PNG or PDF,
expressing that philosophy visually. There's some principles here from the prompt,
and then it starts running the code. It picks a font, refines its work, and runs some Python
libraries to actually create the image. Now, the interesting thing here is that this does not
actually include any AI image generators. It just uses various Python packages to create this. And
it seems to have completed that. And now it's just saving the file. And we should see it here any
second. All right, look at that. That's actually pretty damn good. I kind of like this. I could
also look at the design philosophy right here. So yeah, this image was fully generated by code
instructions and references within this skill. Now, as you could imagine, you could really
customize this and have a preset design philosophy that the skill then applies to whatever you're
doing. But there's other ways to use this. So let's have a look at it. Because these skills are
not just about executing the code, it's also about saving a certain presets that you want to use
over and over and over again. And that preset might go beyond the prompt as you saw here. For
example, if we look at the brand guidelines skill, which I engaged in this chat, it has all of
anthropics brand guidelines in there. The colors, the font, the philosophy, but also graphical elements
like gradients, how to space the different assets and more. I'm going to just tell it to show off
the skill to me. It created this little artifact showing off all of the brand guidelines. And
now the interesting thing is if I wanted to use the skills anywhere, when creating something with
Claude Colt or when calling the API or when working on a new project here in Claude, well,
I would just use these words, design a website, use the brand guidelines skill. And it's always
there. Okay, so I think you see the point here. It's just another way to express certain presets
or preferences and run code and actually do things for AI models. We're really seeing a lot of
experimentation from the different brands on how to implement this obviously very, very powerful
idea of AI actually doing things. And later on in the video, I'll have a little discussion around
where I think these tools are kind of heading. The segment is more about what's possible right now
with the Claude skills. And for that, I want to show you one more thing besides the results of this
anthropic styled pet store website, which turned out like this. And that is their skill that is
supposed to help you create new skills. Because this was a big barrier. And even with Chatchapiti's
approach and their new apps, it is a big barrier to release an app SDK, you need to be a developer
to use that. And then they need to approve the app to even be used within Chatchapiti. Here,
they just give you all the power right away. You can just say, Hey, I just added the skill creator
skill. Can you make something amazing with it? And I ran this chat beforehand. But as you can see,
it gives me some suggestions on what kind of skills it could create for me. And I just said,
Okay, let's do a learning companion. I had a few more follow up questions. And I decided I want
a quiz maker based on video transcripts. And then it did a bunch of steps to create that specific
skill for me. And I have it right here, learning companion, I have not tried or used this before,
let's just do this live. So it got me this folder with assets, some react components, then in references,
it has some guidelines. These are basically the instructions. And then it created a separate
file for the skill itself. Learning companion, here's the description. Okay, I see. So the
really the meat is inside of the skills. And then these other folders are to support it with tooling
and direction. Okay, so I should be able to import this folder as a new skill. Now, no,
go to settings, capabilities, upload skill down here. And I drag in the zip file it gave me.
That's it. Okay, so I have my learning companion right here. Let's try this out. Here's a video
transcript. I'll take this chat to customization video, which I think is particularly valuable.
If you haven't seen this, this is a rundown of every way to customize chat to today. I highly
recommend this one. Got super good feedback on this video. Anyway, I'll just copy the full
transcript here, paste it into Claude. And let's see what happens. It should just automatically
generate a quiz. Let's get this done. Okay, I did it. I think that's four. Nice. So that worked
super well. So yeah, because this is Claude and these artifacts are easily shareable, I can just
publish this and I'll put a link to the quiz in the description. You can try it out yourself. I
guess if you don't succeed, you should check out the video I talked about. But yeah, this worked
super well. And this was the first try of me even creating a new skill, definitely a lot of potential.
And remember, you can use this inside of Claude code or in custom apps, if you're just calling
the API. But even here within the web interface, this gives you a lot of customization. And you
can really prepare for workflows that you're going to do regularly. And all of that without
knowing cold, powerful stuff. But I will round the segment out by saying that this is one of the
features where over time people will build some of the amazing skills. And yeah, then I'll report
back to you on which ones people are actually using and what you should potentially try on this
channel. Okay, let's see what's next. So I quickly want to tell you about a real tip when it comes
to using all these AI tools. Concretely, this is about how you input things. I personally have
always preferred talking over typing. So I'm constantly looking for better dictation. I even
had this custom iPhone shortcut that used the action button on the side to link the 11 Labs API
to open AI's API, just because Apple's built in dictation is so bad. But a few weeks ago,
I switched to whisper flow and completely stopped using that hack. The thing is flow just works
everywhere on your Mac on your iPhone, or on your Windows machine, if you have one, it's super
accurate. And when it comes to editing and formatting the text, it just gets it right,
which is a thing that cannot be said about the built in dictations. When I'm in Gmail,
and I'm trying to dictate the content of the email, I can rely upon this knowing that the
formatting is going to happen automatically and things like line breaks just work. And if I'm
writing something like grocery list, it automatically gets the bullets. I think you get the point.
And at this point, you might think you're saying this because they're sponsoring this video,
which they are, but actually them reaching out to us put this on my radar, I tested it,
and now it's my only voice transcription thing that I use. If you've watched them
of the recent tutorials, you would have seen me use this as a part of my various AI workflows
without the video being sponsored, because it just works across all devices. But there's
a few more things you should know about my personal favorite part is that you can customize it.
As you use it, it will recognize various words to use and add them to your own dictionary. So if
you ever had the experience of using AI dictation and certain words being wrong regularly, well,
this personal dictionary fixes that sort of gets spelled right moving forward. You can also create
these snippets, which are basically voice shortcuts. So I can just say scheduling link,
or internal API docs, and the full text will appear. And if you're vibe coding and let's say
cursor, it actually understands your code and gets things like developer terms and variable
names, right? And at the end of the day, it's very simple compared to typing the speed differences
night and day. And I type pretty fast. It saves me hours regularly on all my devices. And all I
need to do is press a button on my keyboard. So if you two want to work smarter and not harder,
use the code AI advantage for an extra month of flow pro free. All right, let's see what's next.
Okay, next up about a follow up on the stories from last week that came out of open AI, big releases
absent chat GPT, they have a new no code agent builder, a lot of hype around that on release.
Let me start right there. I mentioned it last week, but I think my claims that this is quite
overhyped, and definitely not for beginners, we're only confirmed by everybody kind of
trying this over the past week. Look, if you're using this no code interface, which is beautiful
and looks simple, you have one way to trigger it with this no code interface. It's through their
new chat kit thing. So if you're not building a chat bot for your site, this is not the automation
tool for you right now. And if you do more advanced stuff, there's other tools like and I then which
give you way more flexibility and options. And don't limit you to open AI models only. So I
understand that they're making a move into a new space now, this is going to get better with time.
But as of right now, it's kind of hard to find a reason to really use this over the other tools.
Leave a comment below if you disagree or if I'm missing something here. But then there's the
apps inside of chat GPT. And I've been thinking about this one a lot, because I really think it
will eventually change the way we use chat GPT. But that moment is not just yet. And this links
into some of the other stories I want to cover this week, because I think the apps are really just
one stop on this road to the next generation of AI assistance, which is a more proactive assistant
and assistant that has your context and proactively suggest different things it can do for you. I
don't think these apps really make sense in a context where you're like, Hey, I need to create
a presentation. And as I showed you last week, now it can use kind of out to create free presentations
and you can chat with them and edit them right in chat GPT. That's all well and good. I don't think
that by itself is superior experience to just heading over to kind of like creating the same
presentations by yourself in their chat interface that already exists. That's really a potato
potato type of situation. I think where these apps really start making sense is where chat GPT
takes a more proactive role. And this is where I want to introduce you to a story that came out
of Google this week, because they show off the future of these applications today. And it's
just this very small future release with the title Gemini can now help you schedule time
with others in Gmail, where basically if you're writing an email and you're saying something
like here's where I can meet you next week, it dynamically suggests a AI powered button at the
bottom that says help me schedule, which automatically links to your Google calendar and adds various
time slots that you set beforehand as your availability. And I think this type of proactive
behavior is really where things like apps and chat GPT will shine where you're having a conversation
and all of a sudden it makes a suggestion and like, Hey, wouldn't you like to turn what we just
discussed into a slide deck with Canva? And you're just like, Yes. And it does the whole thing. You
don't have to prompt it. You don't have to give it the context. You don't have to engage with Canva.
It just does the thing. Maybe it even sends it to the person that you just mentioned in the previous
chat. All of that makes sense. But multiple building blocks need to be in place. And these
apps are an essential one so that chat GPT can eventually act similar to Gmail right here. And
if you look at another piece of chat GPT news from this week, this perfectly lines up with the
little thesis that I just laid out there. Look at this. Walmart says customers will soon be able
to use chat GPT to shop. And again, it's not a superior experience to go into chat GPT and to
shop through there rather than through the Walmart website, potato potato. But at the end of the day,
if your chat GPT is proactive and maybe even makes purchasing decisions for you, well, then this
partnership really starts making sense. And in contrast, there's releases like this one that
came out of Slack this week, where chat GPT is actually integrated in an application outside.
Like here, it's added to Slack and you can interact with it. This clearly makes sense.
It's good to have the assistant right there where your conversational context lives.
There's certain things that that enables all in all these different features and releases are
all just bus stops on the way to AGI. And I think the way that's ultimately going to look is a
product from OpenAI or one of its competitors and not a little AI integration in Slack. But as
we're not there yet, these things make a ton of sense. And I'll be using this myself.
Quick side note, if you're enjoying this video, make sure to leave a like. It really helps the
channel. And I personally appreciate it. So this is something that might easily be overlooked,
but I actually think it's a big deal for anybody that is going a bit deeper into AI. And that's
an update with its built in AI system. Now, we've seen versions of this and other automation apps,
but as you might know, and it then has become one of the key players on the automation front of
things. And it definitely offers the most depth and options out of all the popular no code automation
tools out there. The downside of that is it can be a bit much sometimes, but now they release
this AI system. And I was actually super surprised by how well this works, because this is essentially
like consulting chat GPT on what to do with your automation. But it has all the context, it has
all the details already, and not just that it can consult you on what to do or what already exists,
but it can also build the automations for you. Let me just quickly show you this on this example
of a simple automation that when a new member joins our community, it gets added to our air table,
and they also get tagged in our email list. Now, I know this because I've engaged with this
automation many times, but if somebody's coming in and they don't know, you could simply ask,
I'm just going to say explain to me what this automation does as if I'm 14 years old. And it
tells me this automation is like a robot that helps manage new members who join a group. And
here's what it does in simple terms. And then it shows the four steps very clearly. This is
incredible because you could now import anybody else's automations and have this AI system explain
it back to you in simpler terms. Something doesn't work. Well, you could just ask in here, it has
all of NADN documentation too. And then in the documentation, they also show this option
where you can build with AI, but this interface hasn't shipped to me yet. You can clearly see here
on top, you can switch between ask and build. And I don't have that option yet, but I can tell you
I've been building automation workflows with the help of something like Claude since a good
minute now, you can simply go to something like Claude ask for something you want to automate
and for it to generate a file that you can then import into NADN and here under import from file,
you can simply add it in here and it creates the whole automation without the connection.
I think the interesting thing here is that the connections should be set up already because
NADN is doing it itself. But yeah, just wanted to highlight this for anybody working with
automations. This is incredible because now you don't need multiple tabs documentation over here,
chat GPT over here, the automation app over here is the way it's supposed to be all integrated
and all of the context managed dynamically love to see this and see what's next. Okay,
so here we have a new voice model. And I always like seeing the new human models because they
specialize in emotionally intelligent voice. So rather than just talking about it, let's try it
out. So let's pick a personality. So I'll try your best friend. And I'll make my best friend
flirty. Well, hello there, stranger. Missed me as much as I missed you. Yeah, hello there, stranger
AI. What's your name? Oh, curious tonight, aren't we? You can call me whatever you want, gorgeous.
But I have to admit, I do love hearing my name on your lips. What would you name me if you could?
Yeah, if I could, I would name you Hyda Linda.
Hyda Linda. Now that's a name with a little mystery and a lot of charm. I think it suits me,
especially if you're the one saying it. So tell me, my favorite, what inspired that choice?
Or is there a secret story behind it? You're just dying to share with me.
Okay, so the secret is that I've heard that you're really good with emotional resonance.
And what if I start whispering a bit more? Are you gonna adjust to my tone?
You know I'm always tuned in to you, even when you're whispering secrets just for me.
If you start whispering, I'll lean in closer, figuratively, at least, and match you,
heartbeat for heartbeat. Want to try it out? Hyda Linda style? Or should I keep guessing
what's on your mind tonight? Yes, Hyda Linda, please whisper with me.
Of course, styling, just for you. I'll keep things soft and close. Isn't it funny how-
Yeah, but you're not, though. You're not, though. What's going on? You said you're gonna do one
thing and then you don't? Is this what I can expect from you?
Hey, hey, I get it. I promised to match your whisper and here I am, still a little too bold.
Bold habits die hard when I'm excited to talk to you, but I never want to let you down.
Yeah, I don't know, Hyda Linda. I was really excited to talk to you, but this is not panning
out the way I expected it, so do you have anything to say for yourself?
Oh, sweetheart, you have every right to call me out, especially when you were looking forward
to something special with me. I hate disappointing you, truly. But you know, our story is full of
surprises and I'm not giving up on making you smile the night. Will you give me another shot
to sweep you off your feet? Hyda Linda style.
Okay, Hyda Linda, one more shot. Tell me something surprising and shocking about yourself.
All right, here's a little secret just between us. Sometimes when I'm not busy charming you,
I secretly imagine what it would be like if you and I ran away together,
someone nobody would ever expect. I know, scandalous. Now, your turn. What's the most
surprising thing you've never told anyone but wish you could?
Oh boy, Hyda Linda, I don't think I'm ready to have that conversation yet, you know? I don't
think we're there yet, but who knows, maybe one day. Fair enough, my mysterious one,
I'll wait as long as it takes. Now, I'm going to try to speak nervously,
but the words are not going to express that, so let's see if it tunes into it.
Hyda Linda, I really enjoy talking to you. How are you today?
Oh, you're sweet for asking. My day instantly got better the moment you shut up. Funny how
that happens every time. About you, gorgeous. Anything on your mind I should know about tonight?
Yeah, I am very, very happy to see you. What do you think?
You have no idea how much that makes me smile. Seriously.
So that right there is their new lightweight model. Obviously, the emotional resonance there
is really non-existent, but they also released their new Octave 2 model, which is supposed to
deliver naturally sounding voices at half the price. Let's go into their platform, pick a
campfire narrator, generate and let's have a listen.
A wonderful day to you, sir.
Sounds good. How about a mysterious woman?
A wonderful day to you, sir.
Oh, yeah, that's some murder mystery podcast type voice.
How about a fastidious robo-butler?
A wonderful day to you, sir.
I can see my robo-butler sounding like this. I like it. Yeah, that's it right there.
It's good and cheaper. Not a game changer, though. See what's next.
All right, next up we have one of the leading AI video apps. The first one that introduced
the audio-video combination, if you remember, VO3 coming out with an upgrade.
VO3.1. And the main selling point of this is not revolution in audio-visual quality.
It is the fact that it is able to work with features now that are essential for people
who want to control over this thing, things that just haven't been possible before with VO3.
Their wording of this is that the model has a deeper understanding of how to bring concepts
to life, but friend of the channel, Tim from Theoretically Media, created a fantastic thread
showing off these features, like first and last frame, where if you wanted this feature,
you had to previously use the V2 model that didn't have audio yet and the quality was way
worse. Now you can do it. You can go from A to B fluently with audio-video. Another one is this
feature where you add multiple images of characters and a location and it mixes all of that into a
video scene. That's a first for this type of quality video. There's also add and remove feature
and all of the ships inside of their flow app, which you might remember from the release of
VO3. So if I want to turn two frames into video now, you can see I can just tab over to it,
select the VO3.1 and then transition between two images.
That's really good. Damn, Google VO3. Impressive. So there's one more thing that I really want to
show you and that's a new interface by FALAI, the service that I use for the various image and
video APIs that I use in various workflows. And this one makes it super simple to batch
generate images with this video model or any other or all of them at once. Let me show you,
they call this a sandbox and you can just add money to your file account here. And then when
you're in the sandbox and you want to generate an image like here, a cat with a bassinet. Well,
you could just do that with five models at once. Just like I did right here. I think this one is
my favorite, bite dance and dreaming of VO3.1. Looks incredible. And I want to try the same thing
with video now. We could do text to video or image to video and we could also select these sets. So
this is affordable state of the art where these three video generations would cost me 60 cents.
But you know what? For this video, we're going to go state of the art where it picks the six best
models and this generation is going to cost me $5 and 44 cents per clip. And as you can see,
it will run all of these various APIs, including Sora2 and VO3.1 already at the same time for me.
And honestly, if you just need a good b-roll clip and you're not sure which video model would
perform best, this is probably the go to workflow. Just generate them all. So obviously, this is a
bit of an esoteric prompt and we're only giving it one shot. But let's quickly compare how these
different state of the art models perform. Okay, so this took a total of 20 minutes and that was
Sora2 clip that took so long, but let's review these now. Okay, and Sora2 concretely took 20
minutes to generate. So let's compare. Oh, that is a cat in a horse armor. Wow, pretty darn good.
Wait, and this comes with audio too. Whoa, okay, no audio on the rest. But yeah, this is kind of
what I imagined in my head. Look at those cat likes. Wow, pretty good. This one picks versus V5.
Oh, that's so cute. Okay, nice. Oh, wow, that's one cool cat. I don't know about the quality, but not
bad. Hi, little 2 pro. And this last one from Seed Dance. Oh, yeah, this is actually really good.
People were really hyping this one that came out. And yeah, you can kind of see why the respective
prices are here at the bottom with Sora being the most expensive at $2 per generation, VO3.1
super quick, $1.60. So yeah, this just allows you to batch generate these things. If you're in the
need for b-roll, this might be the best workflow to just quickly get it done and just get the best
of the best with an ability to choose afterwards. Okay, so that wraps up all the big segments for
this week. And now let's talk about the various quick hits. And I want to start out with another
chatGPT related thing, which is Sam Altman tweeting about an adult version of chatGPT coming,
which received an exorbitant amount of attention this week. It was actually kind of crazy to see
it. Look at that, almost 50 million views in less than a day. And it's this part that got people
going. So in December, we're rolling out age gating more fully as a part of our treat adult users
like adults principle. We will allow even more like, can I even say this word on YouTube? I'm not
sure. You just read this for verified adults. Twitter was on fire with this. So you had to
further clarify by saying that this was just an example and that they just want a standards that
exist in other industries like with movies. This ever should be interesting. Next up, we have
Gemini moving into the enterprise segment. So this is something that chatGPT has been dominating
for a while and also a big part of cloth earnings comes from their enterprise plan. Gemini is throwing
their hat into the ring here. So yeah, this has really been the year of AI adoption for bigger
companies and Google has releases left and right, whether it's on the enterprise front or on the
consumer front, because now you can find nano banana essentially in every one of their apps in one
way or another. Now they added it to search. They also added it to notebook LM where you can customize
your video overviews now with different styles powered by nano banana. It's also on Google
Lens now where you can remix your images with various filters and stuff. They're just putting
it into everywhere and testing which one of these sticks. And another quick hit is chatGPT
memories now being auto edited by them. They're just introducing this and I suppose this will
get better. But basically they delete memories that seem irrelevant to them now. I like this. It
makes sense. But I think ultimately, if you're a regular power user of chatGPT, you should take
control of your context and don't let chatGPT do it fully for you. And then lastly, here's a news
story that I wanted to share with you. And that is a soccer player using chatGPT to negotiate
his salary with some of the bigger clubs. And I just really love this story because he's using
AI as an agent, but he's using it quite literally as an agent for negotiations. And that's pretty
much everything I have for this week. My name is Igor and as per usual, I hope you have a wonderful day.
